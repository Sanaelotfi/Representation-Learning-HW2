# IFT6135: Representation Learning, first assignement.

## Description

This is the first assignement of the [IFT6135: Representation-Learning](https://sites.google.com/mila.quebec/ift6135), taught by Prof. [Aaron Courville](https://mila.quebec/en/person/aaron-courville/).

## Theory

Optimization, Regularization, and Recurrent Neural networks (RNNs) : [Statement and Solution](https://github.com/Sanaelotfi/IFT-6135-Representation-Learning-HW1/blob/master/IFT6135_HW1_Theory.pdf).


## Practice

This is a joint work with Abderrahim Khalifa, Yann Bouteiller and Amine Bellahsen. 

### Problem 1: building a Multilayer Perceptron (MLP) and training it on the MNIST handwritten digit dataset

[Solution](https://github.com/Sanaelotfi/IFT-6135-Representation-Learning-HW1/blob/master/Problem1.ipynb).

Best model validation accuracy:  98.41%. 


### Problem 2: training a convolutional network on MNIST

[Solution](https://github.com/Sanaelotfi/IFT-6135-Representation-Learning-HW1/blob/master/Problem2.ipynb).

Obtained test accuracy: 99.14 %.

### Problem 3: Dogs vs. Cats InclassKaggle challenge for image classification.

[Solution](https://github.com/Sanaelotfi/IFT-6135-Representation-Learning-HW1/blob/master/Problem3.ipynb).

You can use the to_npy.py file to generate the data.npz file from raw images.

Best validation accuracy: 89%.



We couldn't push large weights to github. Therefore, we provide a link to our working folder on Google Drive in which you can find the full project:

https://drive.google.com/drive/folders/17DuvZv99KrXLqBNPsPaKCEnakqu0lNWf?usp=sharing
